{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERNAME = 'Data'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "import os\n",
    "# sys.path.append('/content/drive/Shared drives/ACMLab Project/{}'.format(FOLDERNAME))\n",
    "\n",
    "# %cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16zpallnoagi.csv     lightning_logs  tiles_to_income_test.csv\tworldelev.npy\r\n",
      "get_tile_incomes.py  model.pth\t     tiles_to_income_train.csv\tziplatlon.csv\r\n",
      "imagery\t\t     pretrained.pth  util.py\r\n",
      "images.ipynb\t     test_imagery    webmercator.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the standard ML libraries...\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd                     # to process our data\n",
    "import matplotlib.pyplot as plt         # graphing\n",
    "import numpy as np                      # matrices\n",
    "\n",
    "import torch\n",
    "import torchvision                      # for MNIST dataset/working with images\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_incomes_data_train = pd.read_csv('tiles_to_income_train.csv')\n",
    "msk = np.random.rand(len(tile_incomes_data_train)) < 0.8\n",
    "train = tile_incomes_data_train[msk]\n",
    "test = tile_incomes_data_train[~msk]\n",
    "\n",
    "tile_incomes_data_test = pd.read_csv('tiles_to_income_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_to_avg_income_train = {}\n",
    "for row in train.iterrows():\n",
    "    tiles_to_avg_income_train[(int(row[1][0]), int(row[1][1]))] = row[1][2]\n",
    "    \n",
    "tiles_to_avg_income_test = {}\n",
    "for row in test.iterrows():\n",
    "    tiles_to_avg_income_test[(int(row[1][0]), int(row[1][1]))] = row[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tiles_to_avg_income_test[key] for key in tiles_to_avg_income_test.keys()] + [tiles_to_avg_income_train[key] for key in tiles_to_avg_income_train.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [tiles_to_avg_income_train[key] for key in tiles_to_avg_income_train.keys()]\n",
    "test_labels = [tiles_to_avg_income_test[key] for key in tiles_to_avg_income_test.keys()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([25., 49., 36., 21., 29., 23., 34., 14., 23.,  7.,  0.,  3.,  3.,\n",
       "         0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  7.,  3.,  2.,  2.,  0.,\n",
       "         1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,\n",
       "         5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.]),\n",
       " array([ 26.77940638,  38.93114419,  51.08288201,  63.23461982,\n",
       "         75.38635764,  87.53809545,  99.68983326, 111.84157108,\n",
       "        123.99330889, 136.14504671, 148.29678452, 160.44852234,\n",
       "        172.60026015, 184.75199797, 196.90373578, 209.0554736 ,\n",
       "        221.20721141, 233.35894923, 245.51068704, 257.66242486,\n",
       "        269.81416267, 281.96590049, 294.1176383 , 306.26937612,\n",
       "        318.42111393, 330.57285175, 342.72458956, 354.87632738,\n",
       "        367.02806519, 379.17980301, 391.33154082, 403.48327864,\n",
       "        415.63501645, 427.78675427, 439.93849208, 452.0902299 ,\n",
       "        464.24196771, 476.39370552, 488.54544334, 500.69718115,\n",
       "        512.84891897, 525.00065678, 537.1523946 , 549.30413241,\n",
       "        561.45587023, 573.60760804, 585.75934586, 597.91108367,\n",
       "        610.06282149, 622.2145593 , 634.36629712]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_labels, bins=50)\n",
    "plt.hist(test_labels, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(labels)\n",
    "std = np.std(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.30363299717398"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder, tiles_to_avg_income, transforms = None):\n",
    "        self.img_shape = (256,256,3)\n",
    "        self.img_data = []\n",
    "        self.label_data = []\n",
    "        self.length = len(tiles_to_avg_income)\n",
    "        for tile in tiles_to_avg_income:\n",
    "            image_name = \"/14_\" + str(tile[0]) + \"_\" + str(tile[1]) + \".jpg\"\n",
    "            img = cv2.imread(folder + image_name)     #.flatten()\n",
    "            self.img_data.append(img)\n",
    "            self.label_data.append(tiles_to_avg_income[tile])\n",
    "        self.img_data = np.array(self.img_data).squeeze()\n",
    "        self.img_data = np.squeeze(self.img_data)\n",
    "        self.label_data = np.array(self.label_data)\n",
    "        if (transforms != None):\n",
    "            self.label_data = np.clip(self.label_data, 0, 500)\n",
    "        self.label_data -= mean\n",
    "        self.label_data /= std\n",
    "        self.images = np.array(self.img_data)\n",
    "        self.labels = np.array(self.label_data)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length # this should return the number of elements in your dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        transform = None\n",
    "        if (self.transforms != None):\n",
    "            transform = self.transforms[random.randrange(0,len(self.transforms))]\n",
    "        if (transform is not None):\n",
    "            image = transform(Image.fromarray(np.uint8(image)))\n",
    "            image = np.array(image)\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "        #return image, label # this should return a tuple of (image, label)\n",
    "                              # where `image` is the image as a tensor\n",
    "                              # and `label` is the ground truth label as a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = RandomResizedCrop((256,256), scale=(0.2, 1.0))\n",
    "rotate = RandomAffine(20)\n",
    "translate = RandomAffine(0,(0.3,0.3))\n",
    "hflip = RandomHorizontalFlip(p=1.0)\n",
    "vflip = RandomVerticalFlip(p=1.0)\n",
    "transforms = [crop, rotate, hflip, vflip, translate, None]\n",
    "# transforms = [translate, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\"imagery\", tiles_to_avg_income_train, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(\"imagery\", tiles_to_avg_income_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in1, out):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.act = nn.PReLU()\n",
    "        self.convBlock1 = nn.Sequential(\n",
    "            nn.Conv2d(in1, out, 5, stride = 2,  padding=2),\n",
    "            nn.BatchNorm2d(out),\n",
    "            self.act,\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.convBlock2 = nn.Sequential(\n",
    "            nn.Conv2d(in1, out, 3, stride = 2,  padding=1),\n",
    "            nn.BatchNorm2d(out),\n",
    "            self.act,\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.convBlock3 = nn.Sequential(\n",
    "            nn.Conv2d(in1, out, 7, stride = 2,  padding=3),\n",
    "            nn.BatchNorm2d(out),\n",
    "            self.act,\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        a = self.convBlock1(x)\n",
    "        b = self.convBlock2(x)\n",
    "        c = self.convBlock3(x)\n",
    "        return a+b+c\n",
    "\n",
    "class ConvolutionalNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNet, self).__init__()\n",
    "        self.act = nn.PReLU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        \n",
    "        self.convBlock1 = InceptionBlock(3,32)\n",
    "        self.convBlock2 = InceptionBlock(32,64)\n",
    "        self.convBlock3 = InceptionBlock(64,128)\n",
    "        self.convBlock4 = InceptionBlock(128,256)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convBlock1(x)\n",
    "        x = self.convBlock2(x)\n",
    "        x = self.convBlock3(x)\n",
    "        x = self.convBlock4(x)\n",
    "        x = x.view(-1, 256 * 1 * 1)\n",
    "        x = self.drop(self.act2(self.fc1(x)))\n",
    "        x = self.drop(self.act2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]           2,432\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "             PReLU-3         [-1, 32, 128, 128]               1\n",
      "             PReLU-4         [-1, 32, 128, 128]               1\n",
      "             PReLU-5         [-1, 32, 128, 128]               1\n",
      "             PReLU-6         [-1, 32, 128, 128]               1\n",
      "         MaxPool2d-7           [-1, 32, 64, 64]               0\n",
      "            Conv2d-8         [-1, 32, 128, 128]             896\n",
      "       BatchNorm2d-9         [-1, 32, 128, 128]              64\n",
      "            PReLU-10         [-1, 32, 128, 128]               1\n",
      "            PReLU-11         [-1, 32, 128, 128]               1\n",
      "            PReLU-12         [-1, 32, 128, 128]               1\n",
      "            PReLU-13         [-1, 32, 128, 128]               1\n",
      "        MaxPool2d-14           [-1, 32, 64, 64]               0\n",
      "           Conv2d-15         [-1, 32, 128, 128]           4,736\n",
      "      BatchNorm2d-16         [-1, 32, 128, 128]              64\n",
      "            PReLU-17         [-1, 32, 128, 128]               1\n",
      "            PReLU-18         [-1, 32, 128, 128]               1\n",
      "            PReLU-19         [-1, 32, 128, 128]               1\n",
      "            PReLU-20         [-1, 32, 128, 128]               1\n",
      "        MaxPool2d-21           [-1, 32, 64, 64]               0\n",
      "   InceptionBlock-22           [-1, 32, 64, 64]               0\n",
      "           Conv2d-23           [-1, 64, 32, 32]          51,264\n",
      "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
      "            PReLU-25           [-1, 64, 32, 32]               1\n",
      "            PReLU-26           [-1, 64, 32, 32]               1\n",
      "            PReLU-27           [-1, 64, 32, 32]               1\n",
      "            PReLU-28           [-1, 64, 32, 32]               1\n",
      "        MaxPool2d-29           [-1, 64, 16, 16]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          18,496\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "            PReLU-32           [-1, 64, 32, 32]               1\n",
      "            PReLU-33           [-1, 64, 32, 32]               1\n",
      "            PReLU-34           [-1, 64, 32, 32]               1\n",
      "            PReLU-35           [-1, 64, 32, 32]               1\n",
      "        MaxPool2d-36           [-1, 64, 16, 16]               0\n",
      "           Conv2d-37           [-1, 64, 32, 32]         100,416\n",
      "      BatchNorm2d-38           [-1, 64, 32, 32]             128\n",
      "            PReLU-39           [-1, 64, 32, 32]               1\n",
      "            PReLU-40           [-1, 64, 32, 32]               1\n",
      "            PReLU-41           [-1, 64, 32, 32]               1\n",
      "            PReLU-42           [-1, 64, 32, 32]               1\n",
      "        MaxPool2d-43           [-1, 64, 16, 16]               0\n",
      "   InceptionBlock-44           [-1, 64, 16, 16]               0\n",
      "           Conv2d-45            [-1, 128, 8, 8]         204,928\n",
      "      BatchNorm2d-46            [-1, 128, 8, 8]             256\n",
      "            PReLU-47            [-1, 128, 8, 8]               1\n",
      "            PReLU-48            [-1, 128, 8, 8]               1\n",
      "            PReLU-49            [-1, 128, 8, 8]               1\n",
      "            PReLU-50            [-1, 128, 8, 8]               1\n",
      "        MaxPool2d-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-53            [-1, 128, 8, 8]             256\n",
      "            PReLU-54            [-1, 128, 8, 8]               1\n",
      "            PReLU-55            [-1, 128, 8, 8]               1\n",
      "            PReLU-56            [-1, 128, 8, 8]               1\n",
      "            PReLU-57            [-1, 128, 8, 8]               1\n",
      "        MaxPool2d-58            [-1, 128, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 8, 8]         401,536\n",
      "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
      "            PReLU-61            [-1, 128, 8, 8]               1\n",
      "            PReLU-62            [-1, 128, 8, 8]               1\n",
      "            PReLU-63            [-1, 128, 8, 8]               1\n",
      "            PReLU-64            [-1, 128, 8, 8]               1\n",
      "        MaxPool2d-65            [-1, 128, 4, 4]               0\n",
      "   InceptionBlock-66            [-1, 128, 4, 4]               0\n",
      "           Conv2d-67            [-1, 256, 2, 2]         819,456\n",
      "      BatchNorm2d-68            [-1, 256, 2, 2]             512\n",
      "            PReLU-69            [-1, 256, 2, 2]               1\n",
      "            PReLU-70            [-1, 256, 2, 2]               1\n",
      "            PReLU-71            [-1, 256, 2, 2]               1\n",
      "            PReLU-72            [-1, 256, 2, 2]               1\n",
      "        MaxPool2d-73            [-1, 256, 1, 1]               0\n",
      "           Conv2d-74            [-1, 256, 2, 2]         295,168\n",
      "      BatchNorm2d-75            [-1, 256, 2, 2]             512\n",
      "            PReLU-76            [-1, 256, 2, 2]               1\n",
      "            PReLU-77            [-1, 256, 2, 2]               1\n",
      "            PReLU-78            [-1, 256, 2, 2]               1\n",
      "            PReLU-79            [-1, 256, 2, 2]               1\n",
      "        MaxPool2d-80            [-1, 256, 1, 1]               0\n",
      "           Conv2d-81            [-1, 256, 2, 2]       1,605,888\n",
      "      BatchNorm2d-82            [-1, 256, 2, 2]             512\n",
      "            PReLU-83            [-1, 256, 2, 2]               1\n",
      "            PReLU-84            [-1, 256, 2, 2]               1\n",
      "            PReLU-85            [-1, 256, 2, 2]               1\n",
      "            PReLU-86            [-1, 256, 2, 2]               1\n",
      "        MaxPool2d-87            [-1, 256, 1, 1]               0\n",
      "   InceptionBlock-88            [-1, 256, 1, 1]               0\n",
      "           Linear-89                  [-1, 128]          32,896\n",
      "          Sigmoid-90                  [-1, 128]               0\n",
      "          Dropout-91                  [-1, 128]               0\n",
      "           Linear-92                   [-1, 64]           8,256\n",
      "          Sigmoid-93                   [-1, 64]               0\n",
      "          Dropout-94                   [-1, 64]               0\n",
      "           Linear-95                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 3,623,217\n",
      "Trainable params: 3,623,217\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 86.84\n",
      "Params size (MB): 13.82\n",
      "Estimated Total Size (MB): 101.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(ConvolutionalNeuralNet(), input_size=(3,256,256), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.4814772550300632 Val: 0.5419065651226369\n",
      "Epoch 1: 0.4847436451591184 Val: 0.5169670606229085\n",
      "Epoch 2: 0.48007071371035726 Val: 0.5034466473315763\n",
      "Epoch 3: 0.4736311899706922 Val: 0.5025366890552507\n",
      "Epoch 4: 0.4665974689706024 Val: 0.5442697765884139\n",
      "Epoch 5: 0.4652449432509897 Val: 0.49167734608308444\n",
      "Epoch 6: 0.4619477113800733 Val: 0.4948506339011339\n",
      "Epoch 7: 0.45015162309723583 Val: 0.5846555013298581\n",
      "Epoch 8: 0.45456826419573726 Val: 0.5277107193201476\n",
      "Epoch 9: 0.4513655914854041 Val: 0.5189569427698546\n",
      "Epoch 10: 0.43868932852296016 Val: 0.5106009883685324\n",
      "Epoch 11: 0.4433459598387303 Val: 0.6135136535956998\n",
      "Epoch    12: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 12: 0.4327781052867393 Val: 0.4623156993462364\n",
      "Epoch 13: 0.4281290131299485 Val: 0.6019314547854479\n",
      "Epoch 14: 0.427952431135648 Val: 0.47313800199853684\n",
      "Epoch 15: 0.42124077065643173 Val: 0.4642666826476009\n",
      "Epoch 16: 0.42320397210228067 Val: 0.4580308243683174\n",
      "Epoch 17: 0.42229916782122556 Val: 0.44751608982021085\n",
      "Epoch 18: 0.4180434701688621 Val: 0.4487593784267178\n",
      "Epoch 19: 0.4153541402431882 Val: 0.44981093292757107\n",
      "Epoch 20: 0.41185177858634914 Val: 0.5178853904021071\n",
      "Epoch 21: 0.4152076361959825 Val: 0.5231652276100965\n",
      "Epoch 22: 0.4135700097533085 Val: 0.4455852768933814\n",
      "Epoch 23: 0.41085602200084737 Val: 0.5409121399446559\n",
      "Epoch 24: 0.412087420818517 Val: 0.6292602063852772\n",
      "Epoch 25: 0.4142619509333452 Val: 0.4468383984354169\n",
      "Epoch 26: 0.4077300854327967 Val: 0.685072501771686\n",
      "Epoch 27: 0.40881721684750955 Val: 0.46972337273607484\n",
      "Epoch 28: 0.4133657891654113 Val: 0.5064313387301188\n",
      "Epoch    29: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 29: 0.4013686227156977 Val: 0.4436752918230389\n",
      "Epoch 30: 0.40370565166387856 Val: 0.44122886657714844\n",
      "Epoch 31: 0.3977505688175492 Val: 0.4413850022664249\n",
      "Epoch 32: 0.4016878239242485 Val: 0.4439276216786876\n",
      "Epoch 33: 0.40391856822197747 Val: 0.4414270680919035\n",
      "Epoch 34: 0.39493607320058505 Val: 0.4414205258209958\n",
      "Epoch 35: 0.3942470567643375 Val: 0.4490568727356582\n",
      "Epoch 36: 0.39271359978235354 Val: 0.44187735860258237\n",
      "Epoch    37: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 37: 0.3968207376420231 Val: 0.4392501030358845\n",
      "Epoch 38: 0.39645614110835464 Val: 0.4391535410702025\n",
      "Epoch 39: 0.3980788893763795 Val: 0.43982096987779634\n",
      "Epoch 40: 0.3974194069079754 Val: 0.4433883660482465\n",
      "Epoch 41: 0.39444722402256166 Val: 0.4401729766012459\n",
      "Epoch 42: 0.38867057834505503 Val: 0.44049677669798554\n",
      "Epoch 43: 0.39395329856017247 Val: 0.4413787008552421\n",
      "Epoch 44: 0.39766851091598715 Val: 0.4402423474568963\n",
      "Epoch    45: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 45: 0.39330128126614833 Val: 0.44034749574628707\n",
      "Epoch 46: 0.3961403372041848 Val: 0.44081430467729277\n",
      "Epoch 47: 0.3936155259341937 Val: 0.4400029166159776\n",
      "Epoch 48: 0.3973903874110748 Val: 0.439359703975326\n",
      "Epoch 49: 0.3926104173531981 Val: 0.4408456294609825\n",
      "Epoch 50: 0.39673998537619554 Val: 0.44128059934023706\n",
      "Epoch    51: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 51: 0.3906603586513365 Val: 0.44049532502991345\n",
      "Epoch 52: 0.3975156159678917 Val: 0.4406412209260179\n",
      "Epoch 53: 0.3993313733772312 Val: 0.4401069484879946\n",
      "Epoch 54: 0.39798699922091224 Val: 0.43914222717285156\n",
      "Epoch 55: 0.3924389244729628 Val: 0.44017408325403623\n",
      "Epoch 56: 0.3955168899399283 Val: 0.44000821878478796\n",
      "Epoch    57: reducing learning rate of group 0 to 6.4000e-08.\n",
      "Epoch 57: 0.3931662230213661 Val: 0.43952271718620844\n",
      "Epoch 58: 0.39858244566639445 Val: 0.43953365026480506\n",
      "Epoch 59: 0.39196038524131604 Val: 0.44003809515526676\n",
      "Epoch 60: 0.3972783204151376 Val: 0.4405898527073779\n",
      "Epoch 61: 0.3945478772903237 Val: 0.44132020449068765\n",
      "Epoch 62: 0.3935054445480552 Val: 0.44151154801300363\n",
      "Epoch    63: reducing learning rate of group 0 to 1.2800e-08.\n",
      "Epoch 63: 0.3937180634571298 Val: 0.44096562317207\n",
      "Epoch 64: 0.3981032315925632 Val: 0.4399217599081098\n",
      "Epoch 65: 0.39480492886940993 Val: 0.44049454711809904\n",
      "Epoch 66: 0.3930323322792224 Val: 0.44116347641668224\n",
      "Epoch 67: 0.3920409788465286 Val: 0.44082539724408565\n",
      "Epoch 68: 0.3970975251475792 Val: 0.4419872199309157\n",
      "Epoch    69: reducing learning rate of group 0 to 2.5600e-09.\n",
      "Epoch 69: 0.39164857222894917 Val: 0.44251386297440776\n",
      "Epoch 70: 0.3975617019584895 Val: 0.440812179252963\n",
      "Epoch 71: 0.3980888494996212 Val: 0.4409784180312433\n",
      "Epoch 72: 0.39724715279891354 Val: 0.43987478575201977\n",
      "Epoch 73: 0.3966087392627391 Val: 0.4404625518330128\n",
      "Epoch 74: 0.39383248384757963 Val: 0.4407488722036316\n",
      "Epoch 75: 0.3929035853911943 Val: 0.4400257722509599\n",
      "Epoch 76: 0.3883319136273166 Val: 0.4407056997253626\n",
      "Epoch 77: 0.39490118668218366 Val: 0.4412813154096896\n",
      "Epoch 78: 0.39718651621865586 Val: 0.44160644023491663\n",
      "Epoch 79: 0.38976764037470113 Val: 0.4421230225025997\n",
      "Epoch 80: 0.39240874217764676 Val: 0.44226424116323426\n",
      "Epoch 81: 0.39245723758577766 Val: 0.44159054674793025\n",
      "Epoch 82: 0.39349311606231824 Val: 0.44041599104428863\n",
      "Epoch 83: 0.393712316607146 Val: 0.44083803912478503\n",
      "Epoch 84: 0.39111898276837953 Val: 0.44044784311548435\n",
      "Epoch 85: 0.38606545999980296 Val: 0.4396094624906677\n",
      "Epoch 86: 0.39731458954746945 Val: 0.43952296781051686\n",
      "Epoch 87: 0.3969895683596487 Val: 0.4396568858175961\n",
      "Epoch 88: 0.3912089104075068 Val: 0.44001415890638335\n",
      "Epoch 89: 0.3965822100104772 Val: 0.4401777059144941\n",
      "Epoch 90: 0.40041353028985954 Val: 0.4403566256318076\n",
      "Epoch 91: 0.390365154112401 Val: 0.440845046840837\n",
      "Epoch 92: 0.3892532947352114 Val: 0.44055410782224896\n",
      "Epoch 93: 0.3967417267940504 Val: 0.44038058791958024\n",
      "Epoch 94: 0.3968723425416134 Val: 0.4401383709175188\n",
      "Epoch 95: 0.3938552411682403 Val: 0.44040155248023544\n",
      "Epoch 96: 0.3937801326871453 Val: 0.4408225687697479\n",
      "Epoch 97: 0.394651409542614 Val: 0.44071476776852136\n",
      "Epoch 98: 0.3973333162042592 Val: 0.44068931475434286\n",
      "Epoch 99: 0.39451572691913145 Val: 0.4402132782919822\n"
     ]
    }
   ],
   "source": [
    "cnn_model = ConvolutionalNeuralNet().cuda() # Don't forget to add .to(device=device)\n",
    "criterion = torch.nn.L1Loss(reduction = 'sum')\n",
    "optimizer = torch.optim.AdamW(cnn_model.parameters(), lr = 0.001, weight_decay=0.1) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.2, patience = 5, verbose=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    cnn_model.train()\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda() # Put the labels on GPU as well\n",
    "\n",
    "        optimizer.zero_grad()                 # resets the information from last time\n",
    "        pred_y = cnn_model(images)            # calculates the predictions\n",
    "        loss = criterion(pred_y, labels)      # calculates the loss\n",
    "        loss.backward()                       # gradient descent, part 1\n",
    "        optimizer.step()                      # gradient descent, part 2\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    \n",
    "    cnn_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(testloader):       \n",
    "            output = cnn_model(images.cuda())\n",
    "            labels = labels.cuda()\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(test_dataset)\n",
    "        \n",
    "    print(f\"Epoch {epoch}: {epoch_loss} Val: {val_loss}\")\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = '''Epoch 0: 0.4814772550300632 Val: 0.5419065651226369\n",
    "Epoch 1: 0.4847436451591184 Val: 0.5169670606229085\n",
    "Epoch 2: 0.48007071371035726 Val: 0.5034466473315763\n",
    "Epoch 3: 0.4736311899706922 Val: 0.5025366890552507\n",
    "Epoch 4: 0.4665974689706024 Val: 0.5442697765884139\n",
    "Epoch 5: 0.4652449432509897 Val: 0.49167734608308444\n",
    "Epoch 6: 0.4619477113800733 Val: 0.4948506339011339\n",
    "Epoch 7: 0.45015162309723583 Val: 0.5846555013298581\n",
    "Epoch 8: 0.45456826419573726 Val: 0.5277107193201476\n",
    "Epoch 9: 0.4513655914854041 Val: 0.5189569427698546\n",
    "Epoch 10: 0.43868932852296016 Val: 0.5106009883685324\n",
    "Epoch 11: 0.4433459598387303 Val: 0.6135136535956998\n",
    "Epoch    12: reducing learning rate of group 0 to 2.0000e-04.\n",
    "Epoch 12: 0.4327781052867393 Val: 0.4623156993462364\n",
    "Epoch 13: 0.4281290131299485 Val: 0.6019314547854479\n",
    "Epoch 14: 0.427952431135648 Val: 0.47313800199853684\n",
    "Epoch 15: 0.42124077065643173 Val: 0.4642666826476009\n",
    "Epoch 16: 0.42320397210228067 Val: 0.4580308243683174\n",
    "Epoch 17: 0.42229916782122556 Val: 0.44751608982021085\n",
    "Epoch 18: 0.4180434701688621 Val: 0.4487593784267178\n",
    "Epoch 19: 0.4153541402431882 Val: 0.44981093292757107\n",
    "Epoch 20: 0.41185177858634914 Val: 0.5178853904021071\n",
    "Epoch 21: 0.4152076361959825 Val: 0.5231652276100965\n",
    "Epoch 22: 0.4135700097533085 Val: 0.4455852768933814\n",
    "Epoch 23: 0.41085602200084737 Val: 0.5409121399446559\n",
    "Epoch 24: 0.412087420818517 Val: 0.6292602063852772\n",
    "Epoch 25: 0.4142619509333452 Val: 0.4468383984354169\n",
    "Epoch 26: 0.4077300854327967 Val: 0.685072501771686\n",
    "Epoch 27: 0.40881721684750955 Val: 0.46972337273607484\n",
    "Epoch 28: 0.4133657891654113 Val: 0.5064313387301188\n",
    "Epoch    29: reducing learning rate of group 0 to 4.0000e-05.\n",
    "Epoch 29: 0.4013686227156977 Val: 0.4436752918230389\n",
    "Epoch 30: 0.40370565166387856 Val: 0.44122886657714844\n",
    "Epoch 31: 0.3977505688175492 Val: 0.4413850022664249\n",
    "Epoch 32: 0.4016878239242485 Val: 0.4439276216786876\n",
    "Epoch 33: 0.40391856822197747 Val: 0.4414270680919035\n",
    "Epoch 34: 0.39493607320058505 Val: 0.4414205258209958\n",
    "Epoch 35: 0.3942470567643375 Val: 0.4490568727356582\n",
    "Epoch 36: 0.39271359978235354 Val: 0.44187735860258237\n",
    "Epoch    37: reducing learning rate of group 0 to 8.0000e-06.\n",
    "Epoch 37: 0.3968207376420231 Val: 0.4392501030358845\n",
    "Epoch 38: 0.39645614110835464 Val: 0.4391535410702025\n",
    "Epoch 39: 0.3980788893763795 Val: 0.43982096987779634\n",
    "Epoch 40: 0.3974194069079754 Val: 0.4433883660482465\n",
    "Epoch 41: 0.39444722402256166 Val: 0.4401729766012459\n",
    "Epoch 42: 0.38867057834505503 Val: 0.44049677669798554\n",
    "Epoch 43: 0.39395329856017247 Val: 0.4413787008552421\n",
    "Epoch 44: 0.39766851091598715 Val: 0.4402423474568963\n",
    "Epoch    45: reducing learning rate of group 0 to 1.6000e-06.\n",
    "Epoch 45: 0.39330128126614833 Val: 0.44034749574628707\n",
    "Epoch 46: 0.3961403372041848 Val: 0.44081430467729277\n",
    "Epoch 47: 0.3936155259341937 Val: 0.4400029166159776\n",
    "Epoch 48: 0.3973903874110748 Val: 0.439359703975326\n",
    "Epoch 49: 0.3926104173531981 Val: 0.4408456294609825\n",
    "Epoch 50: 0.39673998537619554 Val: 0.44128059934023706\n",
    "Epoch    51: reducing learning rate of group 0 to 3.2000e-07.\n",
    "Epoch 51: 0.3906603586513365 Val: 0.44049532502991345\n",
    "Epoch 52: 0.3975156159678917 Val: 0.4406412209260179\n",
    "Epoch 53: 0.3993313733772312 Val: 0.4401069484879946\n",
    "Epoch 54: 0.39798699922091224 Val: 0.43914222717285156\n",
    "Epoch 55: 0.3924389244729628 Val: 0.44017408325403623\n",
    "Epoch 56: 0.3955168899399283 Val: 0.44000821878478796\n",
    "Epoch    57: reducing learning rate of group 0 to 6.4000e-08.\n",
    "Epoch 57: 0.3931662230213661 Val: 0.43952271718620844\n",
    "Epoch 58: 0.39858244566639445 Val: 0.43953365026480506\n",
    "Epoch 59: 0.39196038524131604 Val: 0.44003809515526676\n",
    "Epoch 60: 0.3972783204151376 Val: 0.4405898527073779\n",
    "Epoch 61: 0.3945478772903237 Val: 0.44132020449068765\n",
    "Epoch 62: 0.3935054445480552 Val: 0.44151154801300363\n",
    "Epoch    63: reducing learning rate of group 0 to 1.2800e-08.\n",
    "Epoch 63: 0.3937180634571298 Val: 0.44096562317207\n",
    "Epoch 64: 0.3981032315925632 Val: 0.4399217599081098\n",
    "Epoch 65: 0.39480492886940993 Val: 0.44049454711809904\n",
    "Epoch 66: 0.3930323322792224 Val: 0.44116347641668224\n",
    "Epoch 67: 0.3920409788465286 Val: 0.44082539724408565\n",
    "Epoch 68: 0.3970975251475792 Val: 0.4419872199309157\n",
    "Epoch    69: reducing learning rate of group 0 to 2.5600e-09.\n",
    "Epoch 69: 0.39164857222894917 Val: 0.44251386297440776\n",
    "Epoch 70: 0.3975617019584895 Val: 0.440812179252963\n",
    "Epoch 71: 0.3980888494996212 Val: 0.4409784180312433\n",
    "Epoch 72: 0.39724715279891354 Val: 0.43987478575201977\n",
    "Epoch 73: 0.3966087392627391 Val: 0.4404625518330128\n",
    "Epoch 74: 0.39383248384757963 Val: 0.4407488722036316\n",
    "Epoch 75: 0.3929035853911943 Val: 0.4400257722509599\n",
    "Epoch 76: 0.3883319136273166 Val: 0.4407056997253626\n",
    "Epoch 77: 0.39490118668218366 Val: 0.4412813154096896\n",
    "Epoch 78: 0.39718651621865586 Val: 0.44160644023491663\n",
    "Epoch 79: 0.38976764037470113 Val: 0.4421230225025997\n",
    "Epoch 80: 0.39240874217764676 Val: 0.44226424116323426\n",
    "Epoch 81: 0.39245723758577766 Val: 0.44159054674793025\n",
    "Epoch 82: 0.39349311606231824 Val: 0.44041599104428863\n",
    "Epoch 83: 0.393712316607146 Val: 0.44083803912478503\n",
    "Epoch 84: 0.39111898276837953 Val: 0.44044784311548435\n",
    "Epoch 85: 0.38606545999980296 Val: 0.4396094624906677\n",
    "Epoch 86: 0.39731458954746945 Val: 0.43952296781051686\n",
    "Epoch 87: 0.3969895683596487 Val: 0.4396568858175961\n",
    "Epoch 88: 0.3912089104075068 Val: 0.44001415890638335\n",
    "Epoch 89: 0.3965822100104772 Val: 0.4401777059144941\n",
    "Epoch 90: 0.40041353028985954 Val: 0.4403566256318076\n",
    "Epoch 91: 0.390365154112401 Val: 0.440845046840837\n",
    "Epoch 92: 0.3892532947352114 Val: 0.44055410782224896\n",
    "Epoch 93: 0.3967417267940504 Val: 0.44038058791958024\n",
    "Epoch 94: 0.3968723425416134 Val: 0.4401383709175188\n",
    "Epoch 95: 0.3938552411682403 Val: 0.44040155248023544\n",
    "Epoch 96: 0.3937801326871453 Val: 0.4408225687697479\n",
    "Epoch 97: 0.394651409542614 Val: 0.44071476776852136\n",
    "Epoch 98: 0.3973333162042592 Val: 0.44068931475434286\n",
    "Epoch 99: 0.39451572691913145 Val: 0.4402132782919822'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "for line in lines.split(\"\\n\"):\n",
    "    if (\"reducing\" in line):\n",
    "        continue\n",
    "    line = line.split(\" \")\n",
    "    train.append(float(line[2]))\n",
    "    val.append(float(line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(train))\n",
    "plt.plot(np.array(val))\n",
    "plt.title(\"Training vs Validation Curve\")\n",
    "plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "plt.ylabel(\"L1 Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = torch.load(\"model.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.74497\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "with torch.no_grad():\n",
    "    cnn_model.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):       \n",
    "        output = cnn_model(images.cuda()) * std + mean\n",
    "        labels = labels * std + mean\n",
    "        error = (abs(output.squeeze().cpu() - labels)).squeeze().numpy()\n",
    "        errs.append(error)\n",
    "totalErrs = []\n",
    "for err in errs:\n",
    "    for i in err:\n",
    "        totalErrs.append(i)\n",
    "print(np.mean(totalErrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.69643\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):  \n",
    "        labels = labels * std + mean\n",
    "        error = (abs(labels.mean() - labels)).squeeze().numpy()\n",
    "        errs.append(error)\n",
    "totalErrs = []\n",
    "for err in errs:\n",
    "    for i in err:\n",
    "        totalErrs.append(i)\n",
    "print(np.mean(totalErrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.11769\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "with torch.no_grad():\n",
    "    cnn_model.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):       \n",
    "        output = cnn_model(images.cuda()) * std + mean\n",
    "        labels = labels * std + mean\n",
    "        error = (abs(output.squeeze().cpu() - labels)).squeeze().numpy()\n",
    "        errs.append(error)\n",
    "totalErrs = []\n",
    "for err in errs:\n",
    "    for i in err:\n",
    "        totalErrs.append(i)\n",
    "print(np.mean(totalErrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Jeremy/anaconda3/envs/jeremy/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ConvolutionalNeuralNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/data/Jeremy/anaconda3/envs/jeremy/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type InceptionBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn_model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc = nn.Sequential(nn.Linear(512, 256), nn.ReLU(), nn.Linear(256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.0.weight\n",
      "\t fc.0.bias\n",
      "\t fc.2.weight\n",
      "\t fc.2.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = resnet18.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in resnet18.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.357467125753036 Val: 0.38564424445159246\n",
      "Epoch 1: 0.3552654054429796 Val: 0.40567959486132993\n",
      "Epoch 2: 0.34752213849802704 Val: 0.38434275049362737\n",
      "Epoch 3: 0.34073979766280565 Val: 0.39661747347699466\n",
      "Epoch 4: 0.34897104562695486 Val: 0.4113430019712796\n",
      "Epoch 5: 0.3364511621061456 Val: 0.3998685683647211\n",
      "Epoch 6: 0.34450908607065783 Val: 0.3896087207933412\n",
      "Epoch 7: 0.3459161744967129 Val: 0.4147815634734439\n",
      "Epoch 8: 0.3399242471765589 Val: 0.40599924630492273\n",
      "Epoch     9: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 9: 0.3319251255593813 Val: 0.38350708815303164\n",
      "Epoch 10: 0.3236929298077942 Val: 0.39061297987499377\n",
      "Epoch 11: 0.3215346849364158 Val: 0.3859180290333546\n",
      "Epoch 12: 0.3227650787044034 Val: 0.3904618555611938\n",
      "Epoch 13: 0.3144740360334016 Val: 0.3893326111953624\n",
      "Epoch 14: 0.32401554588708087 Val: 0.3996538959280418\n",
      "Epoch 15: 0.3274257977803548 Val: 0.3854815768499444\n",
      "Epoch    16: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 16: 0.3190108068826127 Val: 0.3880907949739999\n",
      "Epoch 17: 0.32278784915042724 Val: 0.3874639977503867\n",
      "Epoch 18: 0.31790413007113877 Val: 0.38484357047255024\n",
      "Epoch 19: 0.3175810825677566 Val: 0.38960255323535337\n",
      "Epoch 20: 0.3180238801125286 Val: 0.38861459189087805\n",
      "Epoch 21: 0.31646794532762423 Val: 0.3883453598857796\n",
      "Epoch    22: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 22: 0.32185500513308896 Val: 0.3874870077536924\n",
      "Epoch 23: 0.32210426397845016 Val: 0.38769093395149623\n",
      "Epoch 24: 0.31977612883956347 Val: 0.38697075669782877\n",
      "Epoch 25: 0.320813038572012 Val: 0.38774438147997337\n",
      "Epoch 26: 0.32092632145688227 Val: 0.38874105119357144\n",
      "Epoch 27: 0.31608053069476305 Val: 0.3885152322532487\n",
      "Epoch    28: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 28: 0.3239765125187196 Val: 0.38860561029754415\n",
      "Epoch 29: 0.30956077659781855 Val: 0.38856281155217304\n",
      "Epoch 30: 0.3145041070497435 Val: 0.3880158166815765\n",
      "Epoch 31: 0.3186923679641105 Val: 0.3897170707257125\n",
      "Epoch 32: 0.3169452761426384 Val: 0.38943836636786916\n",
      "Epoch 33: 0.32787523572407073 Val: 0.38866564305159296\n",
      "Epoch    34: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 34: 0.31891130518030236 Val: 0.38861241131803415\n",
      "Epoch 35: 0.31564731446523514 Val: 0.38774536647935853\n",
      "Epoch 36: 0.3236359221174183 Val: 0.3895017456834334\n",
      "Epoch 37: 0.3115626659763343 Val: 0.38865314956999175\n",
      "Epoch 38: 0.32325111032583514 Val: 0.38770657908307377\n",
      "Epoch 39: 0.3198843876941284 Val: 0.38870618987257466\n",
      "Epoch    40: reducing learning rate of group 0 to 6.4000e-08.\n"
     ]
    }
   ],
   "source": [
    "resnet18 = resnet18.cuda()\n",
    "criterion = torch.nn.L1Loss(reduction = 'sum')\n",
    "optimizer = torch.optim.Adam(params_to_update, lr = 0.001, weight_decay=0.01) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.2, patience = 5, verbose=True)\n",
    "\n",
    "for epoch in range(40):\n",
    "    epoch_loss = 0\n",
    "    resnet18.train()\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda() # Put the labels on GPU as well\n",
    "        labels = torch.clamp(labels, -2, 3)\n",
    "\n",
    "        optimizer.zero_grad()                 # resets the information from last time\n",
    "        pred_y = resnet18(images).squeeze()            # calculates the predictions\n",
    "        loss = criterion(pred_y, labels)      # calculates the loss\n",
    "        loss.backward()                       # gradient descent, part 1\n",
    "        optimizer.step()                      # gradient descent, part 2\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    \n",
    "    resnet18.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(testloader):       \n",
    "            output = resnet18(images.cuda()).squeeze()\n",
    "            labels = labels.cuda()\n",
    "            loss = criterion(output, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(test_dataset)\n",
    "        \n",
    "    print(f\"Epoch {epoch}: {epoch_loss} Val: {val_loss}\")\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.054287\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "with torch.no_grad():\n",
    "    resnet18.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):       \n",
    "        output = resnet18(images.cuda()) * std + mean\n",
    "        labels = labels * std + mean\n",
    "        error = (abs(output.squeeze().cpu() - labels)).squeeze().numpy()\n",
    "        errs.append(error)\n",
    "totalErrs = []\n",
    "for err in errs:\n",
    "    for i in err:\n",
    "        totalErrs.append(i)\n",
    "print(np.mean(totalErrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18, \"pretrained.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
